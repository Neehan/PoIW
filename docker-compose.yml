version: '3.8'

services:
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi
    environment:
      - ADMIN_USERNAME
      - ADMIN_PASSWORD
    expose:
      - "9001"  # Expose only within the Docker network
    command: uvicorn main:app --host 0.0.0.0 --port 9001

  # vllm-openai:
  #   image: vllm/vllm-openai:latest
  #   container_name: vllm-openai
  #   environment:
  #     - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
  #   runtime: nvidia  # To use NVIDIA GPUs
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
  #   volumes:
  #     - ~/.cache/huggingface:/root/.cache/huggingface
  #   expose:
  #     - "9000"  # Map port 9000 on the host to port 8000 in the container
  #   ipc: host  # Use host's shared memory
  #   command: --model neuralmagic/Meta-Llama-3.1-8B-Instruct-FP8 --max-model-len 32000 --gpu-memory-utilization 0.97
  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/selfsigned.crt:/etc/ssl/certs/selfsigned.crt:ro
      - ./nginx/selfsigned.key:/etc/ssl/private/selfsigned.key:ro
    depends_on:
      - fastapi
      # - vllm-openai
